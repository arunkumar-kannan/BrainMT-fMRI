<div align="center">

# BrainMT: A Hybrid Mamba‑Transformer Architecture for Modeling Long‑Range Dependencies in Functional MRI Data

**[Arunkumar Kannan](https://arunkumar-kannan.github.io/), [Martin A. Lindquist](https://sites.google.com/view/martinlindquist/home), [Brian Caffo](https://sites.google.com/view/bcaffo/home)** 

Johns Hopkins University

[![arXiv](https://img.shields.io/badge/Paper-arXiv-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2506.22591)

</div>

---

## ✨ Overview / Highlights

- 🔍 **Motivation:** *TBD – concise statement of the research gap BrainMT addresses.*
- 🧠 **Architecture:** *TBD – one‑sentence summary of the hybrid Mamba‑Transformer design.*
- 📈 **Results:** *TBD – key performance gains on fMRI benchmarks.*

<div align="center">
  <img src="assets/teaser_brainmt.png" width="70%" alt="BrainMT Teaser Figure"/>
</div>

### 📜 Abstract

*Replace this placeholder with the final abstract from your MICCAI 2025 paper. Use italics or blockquotes to keep the text visually distinct and easy to skim.*

---
